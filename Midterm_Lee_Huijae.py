# -*- coding: utf-8 -*-
"""DeepLearning_Midterm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jbzlzgOYCEiF5t_aH7oSDMVa4FAfLuU4

# CNN-LSTM Machine Learning with UFC Crime Dataset

## Introduction

##### Proceed CNN & LSTM method using UFC Crime dataset. UFC Crime dataset has several cases of crime videos, but I used Assault and Burglary dataset. Assault dataset has 47 videos and Burglary dataset contains 87 videos. With CNN & LSTM, it can detect which crime is happening, and it could also predict the future as well.
"""

# Mount my google drive (connect to my google drive account)
from google.colab import drive
drive.mount('/content/drive')

"""## Import Packages"""

import os
import cv2
import numpy as np
import tensorflow as tf
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras.models import Sequential, save_model, load_model
from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,TimeDistributed,LSTM,Dense,Dropout,Activation
from tensorflow.keras.optimizers import Adam
# For process bar in .fit()
from tqdm import tqdm
from tqdm.keras import TqdmCallback

"""## Preprocessing

##### Since some videos have an explanation at the beginning or end of the videos, so delete the first and the last 15 frames from each recorded video. Set Max frame number to 700 from each video, and if less than 700 recorded frames, use padding (copy the last frame and fill to 700). Since we have Train and Test dataset already, we have x_train and x_test.
"""

#Set path to load or to save
set2_path = "/content/drive/MyDrive/DeepLearning/UCFCrime/Dataset2"
train_assault_path = "/content/drive/MyDrive/DeepLearning/UCFCrime/Dataset2/Train/Assault"
train_burglary_path = "/content/drive/MyDrive/DeepLearning/UCFCrime/Dataset2/Train/Burglary"
test_assault_path = "/content/drive/MyDrive/DeepLearning/UCFCrime/Dataset2/Test/Assault"
test_burglary_path = "/content/drive/MyDrive/DeepLearning/UCFCrime/Dataset2/Test/Burglary"
# set case categories for machine learning efficiency
# Assault will be 0 and burglary will be 1
crime_cases = ["assault", "burglary"]

#preprocessing train dataset
all_train_videos = []
# Training Assault case
for video in sorted(os.listdir(train_assault_path)):
    video_path = os.path.join(train_assault_path, video)
    frames = sorted(os.listdir(video_path))[:400]
    images = [load_image(os.path.join(video_path, frame)) for frame in frames]
    all_train_videos.append(np.array(images))
# Training Burglary case
for video in sorted(os.listdir(train_burglary_path)):
    video_path = os.path.join(train_burglary_path, video)
    frames = sorted(os.listdir(video_path))[:400]
    images = [load_image(os.path.join(video_path, frame)) for frame in frames]
    all_train_videos.append(np.array(images))

# Save the dataset
np.save(os.path.join(set2_path, "X_train1.npy"), np.array(all_train_videos))

# preprocessing test dataset
all_test_videos = []

# Test Assault case
for video in sorted(os.listdir(test_assault_path)):
    video_path = os.path.join(test_assault_path, video)
    frames = sorted(os.listdir(video_path))[:400]
    images = [load_image(os.path.join(video_path, frame)) for frame in frames]
    all_test_videos.append(np.array(images))
# Test burglary case
for video in sorted(os.listdir(test_burglary_path)):
    video_path = os.path.join(test_burglary_path, video)
    frames = sorted(os.listdir(video_path))[:400]
    images = [load_image(os.path.join(video_path, frame)) for frame in frames]
    all_test_videos.append(np.array(images))

# Save the dataset
np.save(os.path.join(set2_path, "X_test1.npy"), np.array(all_test_videos))
print("done!")

# Get path from each dataset
PX_train = "/content/drive/MyDrive/DeepLearning/UCFCrime/Dataset2/X_train1.npy"
Py_train = "/content/drive/MyDrive/DeepLearning/UCFCrime/Dataset2/y_train1.npy"
PX_test = "/content/drive/MyDrive/DeepLearning/UCFCrime/Dataset2/X_test1.npy"
Py_test = "/content/drive/MyDrive/DeepLearning/UCFCrime/Dataset2/y_test1.npy"

# Import the dataset from the Google Drive and set up xtrain, ytrain, xtest, and ytest. Use 86 videos and get 300 frames
# 45 videos from Arrest  and 41 videos from Fighting
xtrain = np.load(PX_train)[ :,:300]
ytrain = np.load(Py_train)
xtest = np.load(PX_test)
ytest = np.load(Py_test)

"""## CNN & LSTM"""

# LSTM layer inside the CNN method. First start with high dimension (300, 64, 64, 3)  and then do maxpooling for each 2 by 2 in 64 by 64 with 16 filters
# and then move to second layer and do maxpooling again with 32 filters then we flatten the high dimension to 1 dimension and pass the data to LSTM model
# which uses 64 neurons and 30% dropout and then give the outcome to CNN  model again using 32 neurons but fully connected and
# then lastly left two choices units=2 to decided either Arrest or Fighting.
# * Numbers might change due to the project: trying several cases might change some numbers *
# CNN-LSTM Model
# use sequential() in Keras to make each layers passes outcome to next layer
Crime_CNN_LSTM_model = Sequential()

# -------------------------------- CNN --------------------------------
# Difference compared to normal CNN
# input_shape: (number of frames used (300), height size (64), width size (64), number of colors- normally it is 3: RGB)
# Use TimeDistributed()

Crime_CNN_LSTM_model.add(TimeDistributed(Conv2D(filters=4, kernel_size=(3,3), padding='same'), input_shape=(300, 64, 64, 3)))
Crime_CNN_LSTM_model.add(TimeDistributed(Activation('relu')))
# First maxpooling
Crime_CNN_LSTM_model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))

Crime_CNN_LSTM_model.add(TimeDistributed(Conv2D(filters=8, kernel_size=(3,3), padding='same')))
Crime_CNN_LSTM_model.add(TimeDistributed(Activation('relu')))
# Second maxpooling
Crime_CNN_LSTM_model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))

# We need to do Flatten() because LSTM uses 1 Dimension.
Crime_CNN_LSTM_model.add(TimeDistributed(Flatten()))

# -------------------------------- LSTM --------------------------------
# Since return_sequences=True is removed, we will have only one LSTM layer
# Units is the number of neurons we are using for the first layer (64 neurons will give better result)
Crime_CNN_LSTM_model.add(LSTM(16))
# With smaller dropout we might set smaller epochs (within 64 neurons dropout 50% of them)
Crime_CNN_LSTM_model.add(Dropout(0.7))

# Another layer after LSTM we get result from LSTM and use 16 neurons
# To get better accuracy, use 32 or higher neurons but might have overfitting if over 64
Crime_CNN_LSTM_model.add(Dense(8))
Crime_CNN_LSTM_model.add(Activation('relu'))
Crime_CNN_LSTM_model.add(Dropout(0.7))
# If model gives overfitting then add dropout for this layer.
# Crime_CNN_LSTM_model.add(Dropout(0.3))

# Final layer for classification because we want to see if test video is a case of Arrest or Fighting
# 2 classes (Arrest & Fighting)
Crime_CNN_LSTM_model.add(Dense(2))
# We have Arrest:0 vs Fighting:1
Crime_CNN_LSTM_model.add(Activation('softmax'))

# Set learning_rate and complie
learning_rate = 0.00005
# Here We need to use 'sparse_categorical_crossentropy' instead of 'categorical_crossentropy' because our y data is integer in array.
Crime_CNN_LSTM_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])

# See the whole process from summary()
Crime_CNN_LSTM_model.summary()

# Needed when using A100 GPU (Google collab)
from tensorflow.keras.mixed_precision import set_global_policy
set_global_policy('mixed_float16')

"""## Fit our model with datasets."""

# Train (fit) the CNN-LSTM model and callbacks=[TqdmCallback(verbose=1)] will show process bar (when set verbose=1).
# Without validation_data=(xtest, ytest), we woun't get val accuracy
# Since it requires large GPU RAM, set batch_size = 2

Save_fit_model = Crime_CNN_LSTM_model.fit(
   xtrain, ytrain, batch_size= 8,validation_data=(xtest, ytest), epochs=50,
    callbacks=[TqdmCallback(verbose=1)]
)

# Save trained model to my Google Drive.
# use keras in TensorFlow format to save model
Crime_CNN_LSTM_model.save("/content/drive/MyDrive/DeepLearning/UCFCrime/CNN_LSTM_Model.keras")

print("Finally done!")

"""## Accuracy

##### Draw the accuacry plot to see if our model is learning well, having problems, or to see if there are some changes needed.
"""

# Draw accuracy plot
import matplotlib.pyplot as plt

# Use history to get accuracy and val_accuracy
plt.figure(figsize=(10, 10))
plt.plot(Save_fit_model.history['accuracy'], label='Accuracy Plot', color = "red")
plt.plot(Save_fit_model.history['val_accuracy'], label='Val Accuracy Plot', color = "blue")
plt.xlabel('# of Epoch')
plt.ylabel('Accuracy')
plt.title('Check Model Accuracy')
plt.legend()
plt.grid(True)
plt.show()

"""## Predictioin"""

# Get model from drive (above fitting part, we saved our model in our drive)
Crime_CNN_LSTM_model = tf.keras.models.load_model("/content/drive/MyDrive/DeepLearning/UCFCrime/CNN_LSTM_Model.keras")

# I will use random test video from Burglary to see the result (probably 10th video) -> xtest[12]
# use model.predict() to get result
pred = Crime_CNN_LSTM_model.predict(np.expand_dims(xtest[15], axis=0))
pr = pred[0] * 100
result = pd.DataFrame({"Crime": ["Assault", "Burglary"], "Probability": pr})

print(result)